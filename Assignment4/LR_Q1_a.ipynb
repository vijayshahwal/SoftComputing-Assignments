{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f396d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca28ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LR_Q1_Dataset.txt\") as f:\n",
    "    l=f.readlines()\n",
    "    f.close()\n",
    "exam_score_1 = []\n",
    "exam_score_2 = []\n",
    "y=[]\n",
    "for i in l:\n",
    "    k=i.split(',')\n",
    "    exam_score_1.append(k[0])\n",
    "    exam_score_2.append(k[1])\n",
    "    y.append(k[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d15b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_score_1 = np.array(exam_score_1,dtype=float)\n",
    "exam_score_2 = np.array(exam_score_2,dtype=float)\n",
    "y = np.array(y,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2957f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLYING MEAN NORMALIZATION AND FEATURE SCALING\n",
    "mean_score1 = np.mean(exam_score_1)\n",
    "min_score1 =np.min(exam_score_1) \n",
    "max_score1 =np.max(exam_score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4252e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score2 = np.mean(exam_score_2)\n",
    "min_score2 =np.min(exam_score_2) \n",
    "max_score2 =np.max(exam_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf0ae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.64427405732314,\n",
       " 66.22199808811695,\n",
       " 30.05882244669796,\n",
       " 99.82785779692128,\n",
       " 30.60326323428011,\n",
       " 98.86943574220611)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score1,mean_score2,min_score1,max_score1,min_score2,max_score2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a81fb0",
   "metadata": {},
   "source": [
    "# Dividing the dataset in training and testing and applying feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af920866",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=[]\n",
    "y_train=[]\n",
    "for i in range(70):\n",
    "    dataset_train.append([1,(exam_score_1[i]-mean_score1)/(max_score1-min_score1),(exam_score_2[i]-mean_score2)/(max_score2-min_score2)])\n",
    "    y_train.append(y[i])\n",
    "dataset_train = np.array(dataset_train)\n",
    "y_train=np.array(y_train)\n",
    "#dataset_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736494b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test=[]\n",
    "y_test=[]\n",
    "for i in range(70,100):\n",
    "    dataset_test.append([1,(exam_score_1[i]-mean_score1)/(max_score1-min_score1),(exam_score_2[i]-mean_score2)/(max_score2-min_score2)])\n",
    "    y_test.append(y[i])\n",
    "datset_test = np.array(dataset_test)\n",
    "y_test=np.array(y_test)\n",
    "#dataset_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f5b4e",
   "metadata": {},
   "source": [
    "## SIGMOID\n",
    "$$ \\ sigmoid(Z) = \\frac{1}{(1+e^{-Z})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc96dc",
   "metadata": {},
   "source": [
    "## GRADIENT DESENT\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\sum \\limits _{i=1}^{m} y^i \\log(h_ \\theta(x^i))+(1-y^i)\\log(1-h_\\theta(x^i)) $$\n",
    "$$  \\theta(j) := \\theta(j) - \\sum \\limits _{i=1}^{m}\\frac{\\partial J(\\theta)}{\\partial\\theta} $$\n",
    "$$  \\frac{\\partial J(\\theta)}{\\partial\\theta} = (sigmoid(h_\\theta(x^i))- y^i)x_i(j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13ccaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-1*z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259e8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(Coeff, X_train, Y_train, ind):\n",
    "    diff = 0\n",
    "    for i in range(len(X_train)):\n",
    "        h_theta = 0\n",
    "        for j in range(len(Coeff)):\n",
    "            h_theta = h_theta + Coeff[j] * X_train[i][j]\n",
    "        diff += (sigmoid(h_theta) - Y_train[i]) * X_train[i][ind]\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a6e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGradient(x_train,y_train,alpha = 0.000001,epoch=50000):\n",
    "    coeff=[0,0,0]\n",
    "    for i in range(epoch):\n",
    "        tmp_coeff = coeff.copy()\n",
    "        for j in range(len(coeff)):\n",
    "            tmp_coeff[j] = tmp_coeff[j]-alpha*(slope(coeff,x_train,y_train,j))\n",
    "        coeff = tmp_coeff.copy()\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf200c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printaccuracy(X_test, Y_test, Coeff):\n",
    "    count = 0\n",
    "    for i in range(len(X_test)):\n",
    "        predicted = 0\n",
    "        for j in range(len(Coeff)):\n",
    "            predicted = predicted + Coeff[j] * X_test[i][j]\n",
    "        predicted = sigmoid(predicted)\n",
    "        if predicted > 0.5:\n",
    "            if Y_test[i] == 1:\n",
    "                count += 1\n",
    "        else:\n",
    "            if Y_test[i] == 0:\n",
    "                count += 1\n",
    "    print(\"Accuracy is : \"+ str(count / len(Y_test) * 100))\n",
    "    return count / len(Y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfc3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochaisticSlope(coeff,x_train,y_train,ind):\n",
    "    diff=0\n",
    "    for i in range(len(coeff)):\n",
    "        diff = diff + coeff[i] * x_train[i]\n",
    "    return (sigmoid(diff)-y_train)*x_train[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3649a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochaisticGradient(X_train,Y_train,alpha=0.00001,epochs=5000):\n",
    "    Coeff = [0, 0, 0]\n",
    "    for iter in range(epochs):\n",
    "        for i in range(len(Y_train)):\n",
    "            TempCoeff = Coeff.copy()\n",
    "            for j in range(len(TempCoeff)):\n",
    "                TempCoeff[j] = TempCoeff[j] - (alpha * (stochaisticSlope(Coeff, X_train[i], Y_train[i], j)))\n",
    "            Coeff = TempCoeff.copy()\n",
    "    return Coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe268996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibtchgra(X_train, Y_train, alpha = 0.00001, epochs = 30, batchsize = 20):\n",
    "    LearningRateScaling = alpha\n",
    "    Coeff = [0, 0, 0]\n",
    "    NoOfBatches = int(np.ceil(len(Y_train) / batchsize))\n",
    "    equallyDiv = False\n",
    "    if (len(Y_train) % batchsize == 0):\n",
    "        equallyDiv = True;\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(NoOfBatches):\n",
    "            Summation = [0, 0, 0]\n",
    "            for j in range(len(Coeff)):\n",
    "                for i in range(batchsize):\n",
    "                    if (batch * batchsize + i == len(X_train)):\n",
    "                        break\n",
    "                    PredictedValue = 0.0\n",
    "                    for wj in range(len(Coeff)):\n",
    "                        PredictedValue += Coeff[wj] * X_train[batch * batchsize + i][wj]\n",
    "                    PredictedValue = sigmoid(PredictedValue)\n",
    "                    PredictedValue -= Y_train[batch * batchsize + i]\n",
    "                    PredictedValue *= X_train[batch * batchsize + i][j]\n",
    "                    Summation[j] += PredictedValue;\n",
    "\n",
    "            if (not equallyDiv and batch == NoOfBatches - 1):\n",
    "                for j in range(len(Summation)):\n",
    "                    Coeff[j] -= (Summation[j] / (len(Y_train) % batchsize)) * LearningRateScaling\n",
    "            else:\n",
    "                for j in range(len(Summation)):\n",
    "                    Coeff[j] -= (Summation[j] / batchsize) * LearningRateScaling\n",
    "    return Coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001]\n",
    "epoch = [5,50,500,5000,50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be17936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy_batch =[]\n",
    "for i in alpha:\n",
    "    for j in epoch:\n",
    "        batch_coeff=batchGradient(dataset_train,y_train,i,j)\n",
    "        print('alpha',i)\n",
    "        print('epoch',j)\n",
    "        accuracy_batch.append(printaccuracy(dataset_test,y_test,batch_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44f3139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 83.33333333333334\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 90.0\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n",
      "Accuracy is : 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy_stoch=[]\n",
    "for i in alpha:\n",
    "    for j in epoch:\n",
    "        coeff_stoch = stochaisticGradient(dataset_train,y_train,i,j)\n",
    "        print('alpha',i)\n",
    "        print('epoch',j)\n",
    "        accuracy_stoch.append(printaccuracy(dataset_test,y_test,coeff_stoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ab7099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n",
      "Accuracy is : 86.66666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy_mini=[]\n",
    "for i in alpha:\n",
    "    for j in epoch:\n",
    "        print('alpha',i)\n",
    "        print('epoch',j)\n",
    "        mini_coeff = minibtchgra(dataset_train,y_train,i,j)\n",
    "        accuracy_mini.append(printaccuracy(dataset_test,y_test,mini_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83916aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
